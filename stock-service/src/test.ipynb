{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506d790a",
   "metadata": {},
   "source": [
    "#### PART 1\n",
    "#### Inspect the values for each financial metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa5d6b",
   "metadata": {},
   "source": [
    "#### Part 2 - Query against Financial Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7d755a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_query_debug' from 'utils.utils' (/Users/aleksamihajlovic/Documents/naro-index-advisor/stock-service/src/utils/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, date\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_query, run_query_to_polars_simple, run_query_debug, run_query_to_polars_simple1, run_query_to_polars_simple2\n\u001b[32m      6\u001b[39m pl.Config.set_tbl_rows(-\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m pl.Config.set_tbl_cols(-\u001b[32m1\u001b[39m) \n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'run_query_debug' from 'utils.utils' (/Users/aleksamihajlovic/Documents/naro-index-advisor/stock-service/src/utils/utils.py)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import polars as pl\n",
    "from datetime import datetime, date\n",
    "from typing import Union\n",
    "from utils.utils import run_query, run_query_to_polars_simple, run_query_debug, run_query_to_polars_simple1, run_query_to_polars_simple2\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1) \n",
    "\n",
    "####################################################### EXAMPLE VALUES\n",
    "max_constituents = 100\n",
    "min_volume_eur = 100000\n",
    "selected_countries = ['US', 'CN']\n",
    "selected_sectors = ['Technology']\n",
    "selected_industries = ['Software - Application','Media & Entertainment','Semiconductors', 'Information Technology Services']\n",
    "selected_stocks = ['']\n",
    "\n",
    "kpis = {\n",
    "    'price_to_earnings_ratio_perc': [60, 70, 80, 90, 99, 100],\n",
    "    'gross_profit_margin_perc': [],\n",
    "    'net_profit_margin_perc': [],\n",
    "}\n",
    "\n",
    "index_start_date = \"2015-03-15\"\n",
    "index_end_date = \"2025-08-31\"\n",
    "index_currency = \"EUR\"\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_query(max_constituents, \n",
    "               selected_countries, \n",
    "               selected_sectors, \n",
    "               selected_industries, \n",
    "               selected_stocks,\n",
    "               kpis):\n",
    "    \n",
    "    industries = \"(\" + \", \".join(f\"'{i}'\" for i in selected_industries) + \")\"\n",
    "    sectors = \"(\" + \", \".join(f\"'{s}'\" for s in selected_sectors) + \")\"\n",
    "    countries = \"(\" + \", \".join(f\"'{c}'\" for c in selected_countries) + \")\"\n",
    "    \n",
    "    # Handle empty selected_stocks list to avoid SQL syntax error\n",
    "    if selected_stocks and len(selected_stocks) > 0:\n",
    "        selected_stocks_sql = \"(\" + \", \".join(f\"'{c}'\" for c in selected_stocks) + \")\"\n",
    "        stocks_condition = f\"OR symbol IN {selected_stocks_sql}\"\n",
    "    else:\n",
    "        stocks_condition = \"\"\n",
    "\n",
    "\n",
    "    # If no KPIs provided, select everything basicaly\n",
    "    if not kpis:\n",
    "        kpis = {\n",
    "            'asset_turnover_perc': ['1', '20', '30', '40', '50', '60', '70', '80', '90', '99', '100']\n",
    "        }\n",
    "\n",
    "    kpi_filters = []\n",
    "    for kpi, values in kpis.items():\n",
    "        if values:\n",
    "            quoted_values = [f\"'{v}'\" for v in values]\n",
    "            kpi_filters.append(f\"AND {kpi} IN ({', '.join(quoted_values)})\")\n",
    "\n",
    "    kpi_sql = \"\\n\".join(kpi_filters)\n",
    "    active_kpis = [kpi for kpi, values in kpis.items() if values]\n",
    "    kpi_cols        = \", \".join(active_kpis)\n",
    "    prep3_kpi_cols  = \", \".join(f\"p3.{kpi}\" for kpi in active_kpis)\n",
    "    #prep6_kpi_cols  = \", \".join(f\"prep6.{kpi}\" for kpi in active_kpis)\n",
    "    prep6_kpi_cols = \", \".join(f\"CAST(prep6.{kpi} AS FLOAT8) AS {kpi}\" for kpi in active_kpis)\n",
    "\n",
    "    import time\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SET enable_mergejoin = off;\n",
    "    WITH prep1 AS (\n",
    "        SELECT symbol\n",
    "        FROM raw.stock_info \n",
    "        WHERE (country IN {countries}\n",
    "        AND industry IN {industries}\n",
    "        AND sector IN {sectors})\n",
    "        {stocks_condition}\n",
    "    ),\n",
    "    prep2 AS (\n",
    "        SELECT *\n",
    "        FROM clean.financial_metrics_perc\n",
    "        WHERE 1=1\n",
    "        {kpi_sql}\n",
    "        {stocks_condition}\n",
    "    ),\n",
    "    prep3 AS (\n",
    "        SELECT \n",
    "            p2.symbol, p2.date, p2.fiscal_year, p2.period, p2.reported_currency,\n",
    "            {kpi_cols}\n",
    "        FROM prep2 p2\n",
    "        INNER JOIN prep1 p1 ON p2.symbol = p1.symbol\n",
    "    ),\n",
    "    prep4 AS (\n",
    "        SELECT \n",
    "    hmc.*,\n",
    "    'Q' || (\n",
    "        CASE \n",
    "            WHEN EXTRACT(YEAR FROM hmc.date)::INT = 2013 THEN 4\n",
    "            WHEN EXTRACT(QUARTER FROM hmc.date)::INT = 4 THEN 1\n",
    "            ELSE EXTRACT(QUARTER FROM hmc.date)::INT + 1\n",
    "        END\n",
    "    ) AS next_quarter,\n",
    "    CASE \n",
    "        WHEN EXTRACT(YEAR FROM hmc.date)::INT = 2013 THEN 2013\n",
    "        WHEN EXTRACT(QUARTER FROM hmc.date)::INT = 4 THEN EXTRACT(YEAR FROM hmc.date)::INT + 1\n",
    "        ELSE EXTRACT(YEAR FROM hmc.date)::INT\n",
    "    END AS next_year,\n",
    "            {prep3_kpi_cols}\n",
    "        FROM raw.historical_market_cap hmc\n",
    "        INNER JOIN prep3 p3\n",
    "        ON hmc.symbol = p3.symbol\n",
    "        AND hmc.year = p3.fiscal_year\n",
    "        AND hmc.quarter = p3.period\n",
    "        WHERE hmc.last_quarter_date = TRUE\n",
    "    ),\n",
    "    prep5 AS (\n",
    "        SELECT \n",
    "            p4.*, \n",
    "            RANK() OVER (\n",
    "                PARTITION BY p4.year, p4.quarter \n",
    "                ORDER BY p4.market_cap_eur DESC\n",
    "            ) AS mcap_rank\n",
    "        FROM prep4 p4\n",
    "    ),\n",
    "    prep6 AS (\n",
    "        SELECT *\n",
    "        FROM prep5\n",
    "        WHERE mcap_rank <= {max_constituents}\n",
    "        {f\"OR symbol IN {selected_stocks_sql}\" if selected_stocks and len(selected_stocks) > 0 else \"\"}\n",
    "    ),\n",
    "    prep8 AS (\n",
    "        SELECT \n",
    "            prep7.date,\n",
    "            prep7.symbol,\n",
    "            prep7.currency,\n",
    "            prep7.year,\n",
    "            prep7.quarter,\n",
    "            cast(prep7.last_quarter_date as BOOLEAN) as last_quarter_date,\n",
    "            CAST(prep7.close as FLOAT8) as close ,\n",
    "            CAST(prep7.close_eur as FLOAT8) as close_eur,\n",
    "            CAST(prep7.close_usd as FLOAT8) as close_usd,\n",
    "            CAST(prep6.market_cap as FLOAT8) as market_cap,\n",
    "            CAST(prep6.market_cap_eur as FLOAT8) as market_cap_eur, \n",
    "            CAST(prep6.market_cap_usd as FLOAT8) as market_cap_usd,\n",
    "            {prep6_kpi_cols},\n",
    "            CAST(prep6.mcap_rank as INTEGER) as mcap_rank\n",
    "        FROM raw.historical_price_volume prep7\n",
    "        INNER JOIN prep6\n",
    "        ON prep7.symbol = prep6.symbol\n",
    "        AND prep7.year = prep6.next_year\n",
    "        AND prep7.quarter = prep6.next_quarter\n",
    "        WHERE volume_eur > 100000\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM prep8\n",
    "    --WHERE (EXTRACT(DOW FROM date) = 1 OR last_quarter_date = TRUE)\n",
    "    \"\"\"\n",
    "    df = run_query_to_polars_simple(query)\n",
    "    return df\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "def build_constituent_weights_dict(rebalance_snapshots: pl.DataFrame, mcap_col: str) -> dict:\n",
    "    weights_by_year_quarter: dict = {}\n",
    "    for row in rebalance_snapshots.sort([\"year\", \"quarter\"]).iter_rows(named=True):\n",
    "        year = row[\"year\"]\n",
    "        quarter = row[\"quarter\"]\n",
    "        symbols = row[\"symbol\"]\n",
    "        mcaps = row[mcap_col]\n",
    "        if symbols is None or mcaps is None or len(symbols) == 0:\n",
    "            continue\n",
    "        total_mcap = float(sum(mcaps)) if mcaps is not None else 0.0\n",
    "        if total_mcap <= 0.0:\n",
    "            continue\n",
    "        pairs = [\n",
    "            {\"symbol\": s, \"weight\": float(m) / total_mcap}\n",
    "            for s, m in zip(symbols, mcaps)\n",
    "        ]\n",
    "        pairs.sort(key=lambda x: x[\"weight\"], reverse=True)\n",
    "        if year not in weights_by_year_quarter:\n",
    "            weights_by_year_quarter[year] = {}\n",
    "        weights_by_year_quarter[year][quarter] = pairs\n",
    "    return weights_by_year_quarter\n",
    "\n",
    "\n",
    "def make_index(df: pl.DataFrame, \n",
    "                           index_start_date: Union[date, str, None] = \"2014-01-01\",\n",
    "                           index_end_date: Union[date, str, None] = None,\n",
    "                           index_currency: str = \"EUR\",\n",
    "                           index_start_amount: float = 1000.0):\n",
    "    \n",
    "    # Step 0: Cast decimals to floats\n",
    "    decimal_cols = [name for name, dtype in zip(df.columns, df.dtypes) if dtype.base_type() == pl.Decimal]\n",
    "    df = df.with_columns([pl.col(c).cast(pl.Float64) for c in decimal_cols])\n",
    "\n",
    "    # Step 1: Parse date column\n",
    "    if df.schema[\"date\"] == pl.Utf8:\n",
    "        df = df.with_columns(pl.col(\"date\").str.to_date())\n",
    "    elif df.schema[\"date\"] != pl.Date:\n",
    "        df = df.with_columns(pl.col(\"date\").cast(pl.Date))\n",
    "\n",
    "    # Step 2: Forward-fill prices based on currency\n",
    "    price_col = \"close_eur\" if index_currency == \"EUR\" else \"close_usd\"\n",
    "    mcap_col  = \"market_cap_eur\" if index_currency == \"EUR\" else \"market_cap_usd\"\n",
    "\n",
    "    df = (\n",
    "        df.sort([\"symbol\", \"date\"])\n",
    "          .with_columns([\n",
    "              pl.col(price_col).forward_fill().over(\"symbol\")\n",
    "          ])\n",
    "    )\n",
    "\n",
    "    # Step 3: Rebalance snapshots\n",
    "    rebalance_df = df.filter(pl.col(\"last_quarter_date\") == True)\n",
    "    print(f\"Rebalance df: {rebalance_df}\")\n",
    "\n",
    "    # Use appropriate market cap column based on currency\n",
    "    \n",
    "    rebalance_snapshots = (\n",
    "        rebalance_df\n",
    "        .group_by([\"year\", \"quarter\"])\n",
    "        .agg([\n",
    "            pl.first(\"date\").alias(\"rebalance_date\"),\n",
    "            pl.col(\"symbol\"),\n",
    "            pl.col(mcap_col)\n",
    "        ])\n",
    "    )\n",
    "    constituent_weights_by_year_quarter = build_constituent_weights_dict(rebalance_snapshots, mcap_col)\n",
    "    # Optional: brief debug output\n",
    "    if constituent_weights_by_year_quarter:\n",
    "        some_year = next(iter(constituent_weights_by_year_quarter))\n",
    "        some_quarter = next(iter(constituent_weights_by_year_quarter[some_year]))\n",
    "        print(f\"Sample weights for {some_year} {some_quarter} (top 5):\",\n",
    "              constituent_weights_by_year_quarter[some_year][some_quarter][:5])\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "    # Step 4: Parse index_start_date and index_end_date\n",
    "    if isinstance(index_start_date, str):\n",
    "        index_start_date = datetime.strptime(index_start_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    if isinstance(index_end_date, str):\n",
    "        index_end_date = datetime.strptime(index_end_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "    # Step 5: Find the latest rebalance on or before index_start_date\n",
    "    initial_snapshot = rebalance_snapshots.filter(pl.col(\"rebalance_date\") <= index_start_date)\n",
    "    if initial_snapshot.is_empty():\n",
    "        raise ValueError(f\"No rebalance snapshot found on or before {index_start_date}\")\n",
    "\n",
    "    initial_row = initial_snapshot.sort(\"rebalance_date\", descending=True).row(0, named=True)\n",
    "    initial_weights = {\n",
    "        s: float(m) / float(sum(initial_row[mcap_col]))\n",
    "        for s, m in zip(initial_row[\"symbol\"], initial_row[mcap_col])\n",
    "    }\n",
    "    active_weights = initial_weights\n",
    "    last_rebalance_date = initial_row[\"rebalance_date\"]\n",
    "\n",
    "    # Step 6: Store future quarterly rebalance dates > index_start_date\n",
    "    future_rebalances = {\n",
    "        row[\"rebalance_date\"]: {\n",
    "            s: float(m) / float(sum(row[mcap_col]))\n",
    "            for s, m in zip(row[\"symbol\"], row[mcap_col])\n",
    "        }\n",
    "        for row in rebalance_snapshots.iter_rows(named=True)\n",
    "        if row[\"rebalance_date\"] > index_start_date\n",
    "    }\n",
    "\n",
    "    # Step 7: Pivot prices using appropriate currency column\n",
    "    pivot = (\n",
    "        df.with_columns([\n",
    "            pl.col(\"date\").cast(pl.Utf8)\n",
    "        ])\n",
    "        .select([\"date\", \"symbol\", price_col])\n",
    "        .pivot(index=\"date\", values=price_col, on=\"symbol\", aggregate_function=\"first\")\n",
    "        .with_columns([\n",
    "            pl.col(\"date\").str.to_date()\n",
    "        ])\n",
    "        .sort(\"date\")\n",
    "        .with_columns(\n",
    "            pl.all().exclude(\"date\").fill_null(strategy=\"forward\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pivot = pivot.filter(pl.col(\"date\") >= pl.lit(index_start_date))\n",
    "\n",
    "    print(pivot)\n",
    "\n",
    "    # Step 8: Main loop\n",
    "    index_value = float(index_start_amount)\n",
    "    index_values = []\n",
    "    previous_prices = None\n",
    "    symbol_columns = [c for c in pivot.columns if c != \"date\"]\n",
    "\n",
    "    for row in pivot.iter_rows(named=True):\n",
    "        current_date = row[\"date\"]\n",
    "        price_row = {s: row[s] for s in symbol_columns}\n",
    "\n",
    "        # Check if rebalancing today\n",
    "        if current_date in future_rebalances:\n",
    "            active_weights = future_rebalances[current_date]\n",
    "            previous_prices = {s: price_row[s] for s in active_weights if price_row[s] is not None}\n",
    "            index_values.append((current_date, index_value))\n",
    "            continue\n",
    "\n",
    "        # Initialize previous prices on the start date\n",
    "        if previous_prices is None:\n",
    "            previous_prices = {s: price_row[s] for s in active_weights if price_row[s] is not None}\n",
    "            index_values.append((current_date, index_value))\n",
    "            continue\n",
    "\n",
    "        # Compute daily return\n",
    "        returns = {}\n",
    "        for symbol, prev_price in previous_prices.items():\n",
    "            current_price = price_row.get(symbol)\n",
    "            if current_price is not None and prev_price > 0:\n",
    "                returns[symbol] = current_price / prev_price\n",
    "            else:\n",
    "                returns[symbol] = 1.0\n",
    "\n",
    "        daily_return = sum(\n",
    "            active_weights[s] * returns.get(s, 1.0) for s in active_weights\n",
    "        )\n",
    "        index_value *= daily_return\n",
    "\n",
    "        # Update previous prices\n",
    "        for s in previous_prices:\n",
    "            if price_row.get(s) is not None:\n",
    "                previous_prices[s] = price_row[s]\n",
    "\n",
    "        index_values.append((current_date, index_value))\n",
    "\n",
    "    result_df = pl.DataFrame(index_values, schema=[\"date\", \"index_value\"], orient=\"row\").sort(\"date\")\n",
    "    if index_end_date is not None:\n",
    "        # Cut off the final dataframe at index_end_date (inclusive)\n",
    "        result_df = result_df.filter(pl.col(\"date\") <= pl.lit(index_end_date))\n",
    "    return result_df, constituent_weights_by_year_quarter\n",
    "\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44d34f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import polars as pl\n",
    "from datetime import datetime, date\n",
    "from typing import Union, Dict\n",
    "from utils.utils import run_query, run_query_to_polars_simple, run_query_debug, run_query_to_polars_simple1, run_query_to_polars_simple2\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1) \n",
    "\n",
    "def calculate_benchmark_risk_return(df: pd.DataFrame) -> Dict[str, float]:\n",
    "\n",
    "    default_result = {\n",
    "        \"data_points\": 0,\n",
    "        \"return_eur\": 0.0,\n",
    "        \"return_usd\": 0.0,\n",
    "        \"risk_eur\": 0.0,\n",
    "        \"risk_usd\": 0.0\n",
    "        }\n",
    "\n",
    "    if df.empty:\n",
    "        return default_result\n",
    "    \n",
    "    # if data has gap > 30 days, return default result\n",
    "    df = df.sort_values('date', ascending=False)\n",
    "    df[\"gap\"] = df[\"date\"].diff(periods=-1) \n",
    "    has_gap = (df[\"gap\"] > pd.Timedelta(days=30)).any()\n",
    "\n",
    "    if has_gap:\n",
    "        return default_result\n",
    "    \n",
    "    # Check if we have at least 5 years of data\n",
    "    today = pd.Timestamp.today().normalize().date()\n",
    "    first_date = df['date'].min()\n",
    "    last_date = df['date'].max()\n",
    "    days_between_min_max = (last_date - first_date).days\n",
    "    days_between_today_max = (today - last_date).days\n",
    "    \n",
    "    print('first_date', first_date)\n",
    "    print('last_date', last_date)\n",
    "    print('days_between_min_max', days_between_min_max)\n",
    "    \n",
    "    if days_between_min_max < 5 * 365:\n",
    "        return default_result\n",
    "\n",
    "    if days_between_today_max > 30:\n",
    "        return default_result\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate for both EUR and USD\n",
    "    for currency in ['eur', 'usd']:\n",
    "        col = f'close_{currency}'\n",
    "\n",
    "\n",
    "        ratio = df[col] / df[col].shift(-1)\n",
    "        has_outlier_jump = ((ratio >= 10) | (ratio <= 0.1)).any()\n",
    "        if has_outlier_jump:\n",
    "            return default_result\n",
    "        \n",
    "        # Calculate returns between t0 and t-250\n",
    "        returns = []\n",
    "        values = df[col].values\n",
    "        for i in range(len(values)):\n",
    "            if i + 250 >= len(values):\n",
    "                break\n",
    "            t0_val = values[i]\n",
    "            t250_val = values[i + 250]\n",
    "            if t0_val>=0 and t250_val>=0:\n",
    "                ret = (t0_val / t250_val) - 1\n",
    "                if abs(ret) < 1000 :\n",
    "                    returns.append(ret)\n",
    "        \n",
    "        # Calculate average return\n",
    "        avg_return = sum(returns) / len(returns) if returns else 0.0\n",
    "        \n",
    "        # Calculate risk (std dev of negative returns)\n",
    "        neg_returns = [r for r in returns if r < 0]\n",
    "        risk = 0.0\n",
    "        if neg_returns:\n",
    "            mean = sum(neg_returns) / len(neg_returns)\n",
    "            squared_diff = [(r - mean) ** 2 for r in neg_returns]\n",
    "            risk = (sum(squared_diff) / len(neg_returns)) ** 0.5\n",
    "            \n",
    "        results[f'return_{currency}'] = round(float(avg_return), 4)\n",
    "        results[f'risk_{currency}'] = round(float(risk), 4)\n",
    "        results[\"data_points\"] = len(returns)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb265c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query + fetch duration: 0.07 seconds\n",
      "first_date 2014-01-02\n",
      "last_date 2025-09-08\n",
      "days_between_min_max 4267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>data_points</th>\n",
       "      <th>return_eur</th>\n",
       "      <th>return_usd</th>\n",
       "      <th>risk_eur</th>\n",
       "      <th>risk_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P Merval</td>\n",
       "      <td>^MERV</td>\n",
       "      <td>index</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>2596</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.0802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name symbol   type        date  data_points  return_eur  return_usd  \\\n",
       "0  S&P Merval  ^MERV  index  2014-01-02         2596      0.9481      0.9243   \n",
       "\n",
       "   risk_eur  risk_usd  \n",
       "0    0.0858    0.0802  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_benchmarks():\n",
    "    benchmark_query = \"\"\"\n",
    "    SELECT \n",
    "        name,\n",
    "        symbol,\n",
    "        type,\n",
    "        date,\n",
    "        close_eur,\n",
    "        close_usd\n",
    "    FROM raw.benchmarks \n",
    "    WHERE name IS NOT NULL\n",
    "    AND symbol='^MERV'\n",
    "    ORDER BY type, name\n",
    "    \"\"\"\n",
    "    benchmark_df = run_query(benchmark_query)\n",
    "\n",
    "    unique_benchmarks = benchmark_df[['name', 'symbol', 'type']].drop_duplicates()\n",
    "    processed_benchmarks = []\n",
    "    \n",
    "    # Process each unique benchmark\n",
    "    for _, row in unique_benchmarks.iterrows():\n",
    "        symbol = row['symbol']\n",
    "        \n",
    "        symbol_data = benchmark_df[benchmark_df['symbol'] == symbol]\n",
    "        risk_return = calculate_benchmark_risk_return(symbol_data)\n",
    "        min_date = symbol_data['date'].min()\n",
    "        \n",
    "        benchmark_record = {\n",
    "            'name': row['name'],\n",
    "            'symbol': symbol,\n",
    "            'type': row['type'],\n",
    "            'date': min_date,\n",
    "            'data_points': risk_return['data_points'],\n",
    "            'return_eur': risk_return['return_eur'],\n",
    "            'return_usd': risk_return['return_usd'],\n",
    "            'risk_eur': risk_return['risk_eur'],\n",
    "            'risk_usd': risk_return['risk_usd']\n",
    "        }\n",
    "        processed_benchmarks.append(benchmark_record)\n",
    "    \n",
    "    result_df = pd.DataFrame(processed_benchmarks) \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ce857",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
